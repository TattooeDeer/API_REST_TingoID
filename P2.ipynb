{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "P2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/TattooeDeer/API_REST_TingoID/blob/master/P2.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "jUgJ75rKw7GU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3C4LF4hgxDdg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Pregunta 2\n"
      ]
    },
    {
      "metadata": {
        "id": "t5GkBlTRU-6c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "tYjI2RQPwnl4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "bf36f594-17e2-451b-f839-6f103f8fcc82"
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "!pip install gensim\n",
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(11235813)\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sn\n",
        "from scipy.stats import bernoulli\n",
        "\n",
        "# Tensorflow & Keras imports\n",
        "import tensorflow as tf\n",
        "from keras.layers import Input, RepeatVector, TimeDistributed, Dense, Embedding, Flatten, Activation, Permute, Lambda, CuDNNGRU\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import load_model\n",
        "\n",
        "\n",
        "# model saving\n",
        "!sudo apt-get install libhdf5-serial-dev\n",
        "import h5py\n",
        "\n",
        "from google.colab import files\n",
        "!git clone https://github.com/TattooeDeer/T3-ANN.git\n",
        "%cd T3-ANN\n",
        "!ls\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.5)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (0.19.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.8.4)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (0.98)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2018.8.24)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.3)\n",
            "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.1.13)\n",
            "Requirement already satisfied: botocore<1.12.0,>=1.11.4 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.11.4)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.12.0,>=1.11.4->boto3->smart-open>=1.2.1->gensim) (0.14)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.12.0,>=1.11.4->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n",
            "/bin/sh: 1: sudo: not found\n",
            "Cloning into 'T3-ANN'...\n",
            "remote: Counting objects: 32, done.\u001b[K\n",
            "remote: Total 32 (delta 0), reused 0 (delta 0), pack-reused 32\u001b[K\n",
            "Unpacking objects: 100% (32/32), done.\n",
            "/content/T3-ANN/T3-ANN\n",
            "att.h5\t Enunciado_T3.ipynb  P2.ipynb\tTarea3.ipynb  train_Q-A.csv\n",
            "attW.h5  LICENSE\t     README.md\ttest_Q.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VL42xkHl4Jjf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## a) Carga de los datos en el entorno y análisis descriptivo"
      ]
    },
    {
      "metadata": {
        "id": "LY_FvybPw37X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3c575e56-62db-4176-8e8e-0514e3c92b4c"
      },
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('train_Q-A.csv')\n",
        "test = pd.read_csv('test_Q.csv')\n",
        "\n",
        "print('Train shape: {0}'.format(train.shape))\n",
        "print('Test shape: {0}'.format(test.shape))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train shape: (86821, 3)\n",
            "Test shape: (11873, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fu6HsKm5zWi5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "b687e235-1636-43a8-e130-8dc17220f90c"
      },
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>56be85543aeaaa14008c9063</td>\n",
              "      <td>When did Beyonce start becoming popular?</td>\n",
              "      <td>in the late 1990s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>56be85543aeaaa14008c9065</td>\n",
              "      <td>What areas did Beyonce compete in when she was...</td>\n",
              "      <td>singing and dancing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>56be85543aeaaa14008c9066</td>\n",
              "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
              "      <td>2003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56bf6b0f3aeaaa14008c9601</td>\n",
              "      <td>In what city and state did Beyonce  grow up?</td>\n",
              "      <td>Houston, Texas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>56bf6b0f3aeaaa14008c9602</td>\n",
              "      <td>In which decade did Beyonce become famous?</td>\n",
              "      <td>late 1990s</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         id  \\\n",
              "0  56be85543aeaaa14008c9063   \n",
              "1  56be85543aeaaa14008c9065   \n",
              "2  56be85543aeaaa14008c9066   \n",
              "3  56bf6b0f3aeaaa14008c9601   \n",
              "4  56bf6b0f3aeaaa14008c9602   \n",
              "\n",
              "                                            question               answer  \n",
              "0           When did Beyonce start becoming popular?    in the late 1990s  \n",
              "1  What areas did Beyonce compete in when she was...  singing and dancing  \n",
              "2  When did Beyonce leave Destiny's Child and bec...                 2003  \n",
              "3      In what city and state did Beyonce  grow up?        Houston, Texas  \n",
              "4         In which decade did Beyonce become famous?           late 1990s  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "bxh7VZd7w34l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "799c88b2-dab9-4647-9371-eb229a803815"
      },
      "cell_type": "code",
      "source": [
        "train.describe()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>86821</td>\n",
              "      <td>86821</td>\n",
              "      <td>86821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>86821</td>\n",
              "      <td>86769</td>\n",
              "      <td>64763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>570e469c0dc6ce1900204f03</td>\n",
              "      <td>How old was William IV when he died?</td>\n",
              "      <td>three</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>231</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              id                              question answer\n",
              "count                      86821                                 86821  86821\n",
              "unique                     86821                                 86769  64763\n",
              "top     570e469c0dc6ce1900204f03  How old was William IV when he died?  three\n",
              "freq                           1                                     2    231"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "3rG5hv1Kzg8i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Al parecer el primer problema que observamos es que para preguntas cuya respuesta es cuantitativa, la respuesta dada es expresada en algunos casos en palabras y en otros en números, nuestro primer intento de solucionar esto será explorar si se cumplen patrones para cada tipo de respuesta, por ejemplo, solo las fechas se responden con números u otra regla similar.\n"
      ]
    },
    {
      "metadata": {
        "id": "pVnKEusYw31f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "6644f0cc-3475-441c-8388-9547300d9020"
      },
      "cell_type": "code",
      "source": [
        "test.describe()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>11873</td>\n",
              "      <td>11873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>11873</td>\n",
              "      <td>11864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>5729f5a03f37b31900478606</td>\n",
              "      <td>Who conceptualized the piston?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              id                        question\n",
              "count                      11873                           11873\n",
              "unique                     11873                           11864\n",
              "top     5729f5a03f37b31900478606  Who conceptualized the piston?\n",
              "freq                           1                               2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "4tkbfa8izgFj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Se observa algo interesante analizando la cantidad de valores únicos y de conteo de las columnas `question` y  `answer`: La cantidad de ocurrencias únicas no es igual a la cantidad de registros totales, lo que puede indicar que quizás hay preguntas/respuestas repetidas en el dataset. Se observa un comportamiento similar en el conjunto de test aunque en mucho menor medida"
      ]
    },
    {
      "metadata": {
        "id": "MUg026sAzgIP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "outputId": "ec02c251-b07c-4b46-f11a-a1c87c3c0c98"
      },
      "cell_type": "code",
      "source": [
        "print('10 preguntas más populares:\\n')\n",
        "print(train[\"question\"].value_counts().head(10))\n",
        "print('\\n ----------------------------------------------------------\\n')\n",
        "print('10 respuestas más populares:\\n')\n",
        "print(train[\"answer\"].value_counts().head(10))\n",
        "print('\\n ----------------------------------------------------------\\n')\n",
        "print('10 preguntas más populares (Conjunto de test):\\n')\n",
        "print(test[\"question\"].value_counts().head(10))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 preguntas más populares:\n",
            "\n",
            "How old was William IV when he died?              2\n",
            "On what date was the city liberated?              2\n",
            "What year did Gladstone retire?                   2\n",
            "What type of religion is Buddhism?                2\n",
            "Who did Victoria marry?                           2\n",
            "What is the national bird of Bermuda?             2\n",
            "What was the name of Alonso de Salazar's ship?    2\n",
            "How tall is Mount Olympus?                        2\n",
            "Where is hunting still vital?                     2\n",
            "What does DRM stand for?                          2\n",
            "Name: question, dtype: int64\n",
            "\n",
            " ----------------------------------------------------------\n",
            "\n",
            "10 respuestas más populares:\n",
            "\n",
            "three    231\n",
            "two      206\n",
            "four     171\n",
            "five     133\n",
            "six       90\n",
            "2007      87\n",
            "2006      85\n",
            "2010      75\n",
            "seven     71\n",
            "2009      71\n",
            "Name: answer, dtype: int64\n",
            "\n",
            " ----------------------------------------------------------\n",
            "\n",
            "10 preguntas más populares (Conjunto de test):\n",
            "\n",
            "Who conceptualized the piston?                                    2\n",
            "In what sector are jobs beginning to decrease?                    2\n",
            "What are the main sources of primary law?                         2\n",
            "In what sector are jobs beginning to increase?                    2\n",
            "When was James Hutton born?                                       2\n",
            "What is the population of Los Angeles?                            2\n",
            "What is the CJEU's duty?                                          2\n",
            "Where does heat rejection occur in the Rankine cycle?             2\n",
            "Who designed Salamanca?                                           2\n",
            "In an atmospheric engine, what does air pressure push against?    1\n",
            "Name: question, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Qx826njWzgKh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Las preguntas que más se repiten lo hacen a lo más 2 veces cada una. En cuanto a las respuestas, predominan aquellas que son números escritos como palabras, asi como también números escritos como tal los cuales aprecen ser fechas debido a la cantidad de dígitos y la magnitud que presentan.\n",
        "\n",
        "Lo anterior puede ser en respuesta a un sesgo en la selección de preguntas.\n",
        "\n",
        "Finalmente, se debe notar que el conjunto de test está compuesto solo por preguntas, lo que significa que, de utilizar los conjuntos de la forma en la que están, tendremos un entrenamiento supervisado pero tendremos que encontrar una métrica nueva para evaluar el desempeño final de la máquina.\n",
        "\n",
        "## b) Preprocesamiento\n",
        "\n",
        "Ahora se procederá a preprocesar ambos conjuntos con el objetivo de mejorar el desempeño que tenga la futura máquina al ingerirlos en el entrenamiento.\n",
        "Se _tokenizarán_ las preguntas y respuestas del conjunto de entrenamiento y de test, no realizando mayor modificación de las palabras dado que después necesitaremos reconstruir las oraciones."
      ]
    },
    {
      "metadata": {
        "id": "MnaFR0FIw3yF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_questions = [word_tokenize(sentence.lower()) for sentence in train[\"question\"]] #or processing\n",
        "test_questions = [word_tokenize(sentence.lower()) for sentence in  test[\"question\"]]\n",
        "train_answers = [word_tokenize(sentence) for sentence in train[\"answer\"]]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bSPwafIP39XZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## c) Vocabulario\n",
        "\n",
        "Ahora, se procede a crear un vocabulario para codificar las palabras en las respuestas a generar, esta aproximación nos servirá para paliar el problema mencionado en el punto *a)*, de que no tenemos las respuestas correctas para el conjunto de test."
      ]
    },
    {
      "metadata": {
        "id": "5j3u0M6n39aE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "70d7550c-f7cd-4721-da93-85dddaca793a"
      },
      "cell_type": "code",
      "source": [
        "# Respuestas\n",
        "vocab_answer = set()\n",
        "for sentence in train_answers:\n",
        "  for word in sentence:\n",
        "    vocab_answer.add(word)\n",
        "vocab_answer = [\"#end\"] + list(vocab_answer)\n",
        "print('Posibles palabras para respuestas: ', len(vocab_answer))\n",
        "vocabA_indices = {c: i for i, c in enumerate(vocab_answer)}\n",
        "indices_vocabA = {i: c for i, c in enumerate(vocab_answer)}\n",
        "\n",
        "# Preguntas: Train\n",
        "vocab_question = set()\n",
        "for sentence in train_questions:\n",
        "  for word in sentence:\n",
        "    vocab_question.add(word)\n",
        "vocab_question = [\"#end\"] + list(vocab_question)\n",
        "print('Posibles palabras para preguntas (train): ', len(vocab_question))\n",
        "vocabQTrain_indices = {c: i for i, c in enumerate(vocab_question)}\n",
        "indices_vocabQTrain = {i: c for i, c in enumerate(vocab_question)}\n",
        "\n",
        "print('Diferencia en la cantidad de palabras que componen las preguntas y respuestas (train sets): ', \n",
        "      abs(len(vocab_answer) - len(vocab_question)))\n",
        "\n",
        "# Preguntas: Test\n",
        "vocab_question = set()\n",
        "for sentence in test_questions:\n",
        "  for word in sentence:\n",
        "    vocab_question.add(word)\n",
        "vocab_question = [\"#end\"] + list(vocab_question)\n",
        "print('Posibles palabras para preguntas (test): ', len(vocab_question))\n",
        "vocabQTest_indices = {c: i for i, c in enumerate(vocab_question)}\n",
        "indices_vocabQTest = {i: c for i, c in enumerate(vocab_question)}\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Posibles palabras para respuestas:  47423\n",
            "Posibles palabras para preguntas (train):  39482\n",
            "Diferencia en la cantidad de palabras que componen las preguntas y respuestas (train sets):  7941\n",
            "Posibles palabras para preguntas (test):  10322\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a32CLkBA39cc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "El vocabulario de palabras que componen las respuestas tiene _7941_ elementos más que el que compone las preguntas, esto puede hacer que hayan palabras encontradas en preguntas asociadas a varias palabras de respuesta, haciendo más dificil el discernir la respuesta correcta. Por otro lado, se debe notar la pequeña cantidad de palabras que componen el vocabulario de test."
      ]
    },
    {
      "metadata": {
        "id": "g5mWynT339fD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## d) Codificación de tokens y padding\n",
        "\n",
        "Aplicaremos una codificación tipo *one-hot vector* sobre los tokens, calcularemos el largo máximo que puede tener una respuesta y una pregunta y reformularemos las secuencias de entrada del modelo agregandoles un padding al final, esto hará que el tamaño de input sea constante. Para las preguntas se rellenará con '0' (recordar que las palabras estan indexadas y tokenizadas), mientras que para las respuestas se rellenará con el carácter definido *'#end'* que indica cuando la pregunta ha sido respondida.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "gWfUQCX139jE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# input and output to onehotvector\n",
        "X_answers = [[vocabA_indices[palabra] for palabra in sentence] for sentence in train_answers]\n",
        "X_test_Q = [[vocabQTest_indices[palabra] for palabra in sentence] for sentence in test_questions]\n",
        "X_train_Q = [[vocabQTrain_indices[palabra] for palabra in sentence] for sentence in train_questions]\n",
        "\n",
        "# padding\n",
        "max_input_length = np.max(list(map(len, train_questions)))\n",
        "max_output_length = np.max(list(map(len, train_answers)))\n",
        "\n",
        "X_train_Q = sequence.pad_sequences(X_train_Q, maxlen = max_input_length,\n",
        "                                        padding = 'post', value = 0)\n",
        "X_test_Q = sequence.pad_sequences(X_test_Q, maxlen = max_input_length,\n",
        "                                        padding = 'post', value = 0)\n",
        "X_answers = sequence.pad_sequences(X_answers, maxlen = max_output_length,\n",
        "                                        padding = 'post', value = vocabA_indices['#end'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y985lm4O39lm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## e) Modelo *Encoder-Decoder* con módulos de atención\n",
        "\n",
        "Utilizaremos un encoder basado en GRU."
      ]
    },
    {
      "metadata": {
        "id": "x6DiPDzP39oE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Encoder-Decoder modelo\n",
        "length_output = max_output_length\n",
        "hidden_dim = 128\n",
        "\n",
        "embedding_vector = 64\n",
        "encoder_input = Input(shape = (max_input_length, ))\n",
        "embedded = Embedding(input_dim = len(vocabQTrain_indices), output_dim = embedding_vector,\n",
        "                    input_length = max_input_length)(encoder_input)\n",
        "encoder = CuDNNGRU(hidden_dim, return_sequences = True)(embedded)\n",
        "\n",
        "attention = TimeDistributed(Dense(max_output_length, activation = 'tanh'))(encoder)\n",
        "\n",
        "# softmax a las atenciones sobre todo T\n",
        "attention = Permute([2, 1])(attention)\n",
        "attention = Activation('softmax')(attention)\n",
        "attention = Permute([2, 1])(attention)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_t_mw8tR39qx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Aplicacion de la atencion al modelo\n",
        "def attention_multiply(vects):\n",
        "  encoder, attention = vects\n",
        "  return K.batch_dot(attention, encoder, axes = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fhK96YZB39hg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sent_representation = Lambda(attention_multiply)([encoder, attention])\n",
        "decoder = CuDNNGRU(hidden_dim, return_sequences= True)(sent_representation)\n",
        "probabilities = TimeDistributed(Dense(len(vocab_answer), activation = 'softmax'))(decoder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tNQ7RXP1XcTM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "3b37286a-d36c-477f-9cf2-1fdb1221ca5c"
      },
      "cell_type": "code",
      "source": [
        "model = Model(encoder_input, probabilities)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer = 'adam')\n",
        "model.summary()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 60)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 60, 64)       2526848     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "cu_dnngru_3 (CuDNNGRU)          (None, 60, 128)      74496       embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_3 (TimeDistrib (None, 60, 46)       5934        cu_dnngru_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "permute_3 (Permute)             (None, 46, 60)       0           time_distributed_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 46, 60)       0           permute_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "permute_4 (Permute)             (None, 60, 46)       0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 46, 128)      0           cu_dnngru_3[0][0]                \n",
            "                                                                 permute_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "cu_dnngru_4 (CuDNNGRU)          (None, 46, 128)      99072       lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_4 (TimeDistrib (None, 46, 47423)    6117567     cu_dnngru_4[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 8,823,917\n",
            "Trainable params: 8,823,917\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dfmoHD1_YVU0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## f) Entrenamiento del modelo\n",
        "\n",
        "Se entrenará el modelo con 10 epochs con tamaño de batch 64"
      ]
    },
    {
      "metadata": {
        "id": "adYhTEB2YtX5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8e698d5e-39f1-4f30-85b7-80fe1b9238ac"
      },
      "cell_type": "code",
      "source": [
        "X_answers = X_answers.reshape(X_answers.shape[0], X_answers.shape[1],1)\n",
        "X_answers.shape"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(86821, 46, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "metadata": {
        "id": "PiFOWQc3jgon",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s6HtS8o4UH3_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.load_weights('attW.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bzDkoGONY8Cu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "90c47fa2-6920-4f40-fd56-07b610e36185"
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "BS = 64\n",
        "model.fit(X_train_Q, X_answers, epochs = 10, batch_size = BS,\n",
        "               validation_split = 0.2)\"\"\""
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 69456 samples, validate on 17365 samples\n",
            "Epoch 1/10\n",
            "69456/69456 [==============================] - 356s 5ms/step - loss: 0.9792 - val_loss: 0.8078\n",
            "Epoch 2/10\n",
            "69456/69456 [==============================] - 353s 5ms/step - loss: 0.6997 - val_loss: 0.8136\n",
            "Epoch 3/10\n",
            "69456/69456 [==============================] - 352s 5ms/step - loss: 0.6826 - val_loss: 0.8227\n",
            "Epoch 4/10\n",
            "69456/69456 [==============================] - 352s 5ms/step - loss: 0.6690 - val_loss: 0.8304\n",
            "Epoch 5/10\n",
            "69456/69456 [==============================] - 352s 5ms/step - loss: 0.6557 - val_loss: 0.8415\n",
            "Epoch 6/10\n",
            "69456/69456 [==============================] - 352s 5ms/step - loss: 0.6383 - val_loss: 0.8402\n",
            "Epoch 7/10\n",
            "69456/69456 [==============================] - 352s 5ms/step - loss: 0.6184 - val_loss: 0.8483\n",
            "Epoch 8/10\n",
            "69456/69456 [==============================] - 352s 5ms/step - loss: 0.6006 - val_loss: 0.8469\n",
            "Epoch 9/10\n",
            "69456/69456 [==============================] - 352s 5ms/step - loss: 0.5834 - val_loss: 0.8569\n",
            "Epoch 10/10\n",
            "69456/69456 [==============================] - 352s 5ms/step - loss: 0.5667 - val_loss: 0.8669\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6d07dc1fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "9-0aZ2d359MB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_krsO_gfFOdD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_9_vauVFFOm6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ad677a3f-2c57-4f7f-a95d-7ec642352419"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "4Q2s2436ZNDR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## g) Predicción del modelo\n",
        "\n",
        "Evaluaremos ahora las predicciones del modelo a traves del modelamiento de la distribución de probabilidad de las respuestas, basandonos en la frecuencia de ocurrencia de los tokens encontrados en las mismas.\n"
      ]
    },
    {
      "metadata": {
        "id": "b8b234xdh0Eu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dace73cc-b2c8-4b00-bbfb-ed3047f0227e"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 46, 47423)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "TFpg3tZ__uWQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BDdUwUMJgpnl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "5ddc995d-cdfe-4faf-faa9-6aedeb9e81c2"
      },
      "cell_type": "code",
      "source": [
        "def predict_words(model, example, diversity):\n",
        "  model = load_model('att.h5')\n",
        "  example = np.array(example)\n",
        "  example.reshape((60,))\n",
        "  prediction = model.predict(example)\n",
        "  return prediction\n",
        "  \n",
        "def determine_answer(answer_probs):\n",
        "  Y = np.random.binomial(1, answer_probs, 1)\n",
        "  return Y\n",
        "\n",
        "  \n",
        "n = 10\n",
        "for i in range(n):\n",
        "  indexs = np.random.randint(0, len(X_test_Q)-2)\n",
        "  example = X_train_Q[indexs:(indexs+1)]\n",
        "  indexes_answer = predict_words(model, example, 0.85)\n",
        "  indexes_answer = determine_answer(indexes_answer)\n",
        "  question = test['question'][indexs]\n",
        "  print('Pregunta: ', question)\n",
        "  answer = ''\n",
        "  for index in indexes_answer:\n",
        "    print(index)\n",
        "    if (indices_vocabA[index] == '#end'): # fin de la oracion\n",
        "      continue\n",
        "    else:\n",
        "      answer += indices_vocabA[index]+' '\n",
        "  print('Respuesta: ', answer)\n",
        "print('Los ha predecido todos!')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-2189f191248c>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    n = 10\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "HOhDJADaldqM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DwkGsnCaXVn5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "inv_map = {v: k for k, v in vocabA_indices.items()}\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MagGuISOPdnU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def determine_answer(answer_probs):\n",
        "  Y = np.random.binomial(1, answer_probs, 1)\n",
        "  return Y\n",
        "from copy import copy\n",
        "pred = model.predict(X_train_Q[1:2])\n",
        "pred = pred.reshape(pred.shape[1], pred.shape[2])\n",
        "#X_train_Q[1:2]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AnI0jFvryh2a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4ed5c867-f40e-497a-b905-e5996512f826"
      },
      "cell_type": "code",
      "source": [
        "pred.shape"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46, 47423)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 196
        }
      ]
    },
    {
      "metadata": {
        "id": "EdW4Y1x6qmGU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "51a0309c-8e45-4c53-88f7-071658ac0d41"
      },
      "cell_type": "code",
      "source": [
        "resp_indx = []\n",
        "for i1 in range(pred.shape[0]):\n",
        "  max_prob = 0.\n",
        "  max_prob_indx = 0\n",
        "  for i2 in range(pred.shape[1]):\n",
        "    prob = pred[i1, i2]\n",
        "    if(prob >= max_prob):\n",
        "      max_prob = prob\n",
        "      max_prob_indx = i2\n",
        "  resp_indx = resp_indx.append(max_prob_indx)\n",
        "\n"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-209-7b8ff6490bd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0mmax_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0mmax_prob_indx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mresp_indx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresp_indx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_prob_indx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'append'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "v8zMagSuqsp1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## h) Evaluacion del modelo\n",
        "Para verificar la calidad del modelo, compararemos con el benchmark"
      ]
    },
    {
      "metadata": {
        "id": "p_1NO7R9PdGB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "78241a0b-5726-4049-ee57-152ea3c80c95"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "138"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "metadata": {
        "id": "Ffqf1bH-qsoI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python evaluate-v2.0.py dev-v2.0.json predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X_awuqAZqslg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dic_predictions = {}\n",
        "for example, id_e in zip(Xtest_question, df_test[\"id\"]): # todos los ejemplos\n",
        "  indexes_answer = predict_words(model, example) # predice palabra en cada instante\n",
        "  answer = \"\"\n",
        "  for index in indexes_answer:\n",
        "    if(indices_vocabA[index] == '#end'): # Final de la oracion\n",
        "      continue\n",
        "    else:\n",
        "      answer += indices_vocabA[index]+\" \"\n",
        "  dic_predictions[id_e] = answer\n",
        "  contador += 1\n",
        "  print('Los ha predecido todos!')\n",
        "  json_save = json.dumps(dic_predictions)\n",
        "  archivo = open('predictions', 'w')\n",
        "  archivo.write(json.save)\n",
        "  archivo.close()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}